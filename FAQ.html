<html><head><title>cnn-numpy FAQ</title></head>
<body>
<h1 id="cnn-numpy-faq">cnn-numpy FAQ</h1>
<p>Experiments with implementing a convolutional neural network (CNN) in NumPy.</p>
<p>Written by David Stein (david@djstein.com). See <a href="index.html">index.html</a> for more information.</p>
<p>Also available at <a href="https://www.github.com/neuron-whisperer/cnn-numpy">https://www.github.com/neuron-whisperer/cnn-numpy</a>.</p>
<h2 id="questions-about-cnn-numpy">Questions About cnn-numpy</h2>
<h3 id="how-do-i-run-this-code-">How do I run this code?</h3>
<p>Let&#39;s get this out of the way:</p>
<ul>
<li><p>Make sure you have <a href="https://www.python.org">Python 3</a> installed with requests and NumPy:</p>
<pre><code>  python3 -m pip install requests numpy</pre></code>
</li>
<li><p>Clone the repository, or just download <a href="mnist.py"><code>mnist.py</code></a>, <a href="cnn_numpy.py"><code>cnn_numpy.py</code></a>, and <a href="cnn_numpy_sg.py"><code>cnn_numpy_sg.py</code></a>.</p>
</li>
<li><p>Ensure that you have (a) a working internet connection or (b) a copy of the <a href="http://yann.lecun.com/exdb/mnist/">MNIST handwritten digits data set</a>. Just grab the first four files on the page and save them (with the original filenames) in the same folder as the Python scripts. No need to unzip them.</p>
</li>
<li><p>Run the script:</p>
<pre><code>  python3 mnist<span class="hljs-selector-class">.py</span> cnn
</code></pre></li>
</ul>
<p>This will train a simple CNN against the MNIST data set. You can replace <code>cnn</code> with <code>flat</code> to run a non-CNN fully-connected model instead. You can also append <code>naive</code> to use the naive CNN implementation, which runs much, much slower.</p>
<h3 id="what-s-the-point-of-this-project-">What&#39;s the point of this project?</h3>
<p>For students who want to learn about convolutional neural networks, one of the best-known tutorials is Dr. Andrew Ng&#39;s &quot;Building a Convolutional Neural Network Step By Step&quot; assignment as part of the Coursera sequence on deep learning. However, the code from that example is poorly structured, incomplete, and in fact <em>enormously</em> inefficient - to the point where it is not feasible to see it learn anything. This project is a reimplementation of the code in that project that is cleaner, complete, and adapted for much faster performance (x1,000!) using NumPy.</p>
<h3 id="what-should-i-use-this-code-for-">What should I use this code for?</h3>
<p>As a study tool or reference for machine learning architectures, particularly CNNs.</p>
<p>As a demonstration or proof-of-concept, kind of like a machine with the cover removed. If you want to see a CNN in action - one that&#39;s largely transparent, where you can see and easily understand the details of the layers in action - this project provides some different architectures that successfully classify the MNIST data set.</p>
<p>As an experimental package. You can tweak the hyperparameters: models, training, testing, etc. - and see how the models respond. You can easily build many kinds of models, tweak the code to add activation functions / optimizers / regularizers / normalizers / new layer types / etc., and train your models against the MNIST data set. It is meant to be simple, readable, and extensible.</p>
<h3 id="what-shouldn-t-i-use-this-code-for-">What <em>shouldn&#39;t</em> I use this code for?</h3>
<p>Anything of moderate-or-greater complexity, where training in a reasonable amount of time requires a GPU or a distributed architecture such as a computing cluster. TensorFlow and PyTorch will run circles around this code.</p>
<h2 id="background-questions">Background Questions</h2>
<h3 id="what-s-a-cnn-">What&#39;s a CNN?</h3>
<p>A <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a>, which is a type of artificial neural network that is extremely useful for tasks like detecting shapes and objects in images.</p>
<h3 id="what-s-numpy-">What&#39;s NumPy?</h3>
<p><a href="https://en.wikipedia.org/wiki/NumPy">NumPy</a> is a library for Python that is useful for matrix operations - basically, calculations over huge batches of numbers. The NumPy library is highly optimized for lightning-fast operations - when used correctly, it can be <em>thousands</em> of times faster than plain old Python. Since machine learning requires lots of multiplications of weights with inputs, NumPy is ideal for the kinds of operations that are performed in machine learning.</p>
<h3 id="what-s-jupyter-">What&#39;s Jupyter?</h3>
<p><a href="https://jupyter.org/">Jupyter</a> is a neat way of documenting Python tutorials. A Jupyter &quot;notebook&quot; is a collection of blocks, each of which is either markdown text (like HTML but easier to write) or Python code that you can run in place, view, and modify.</p>
<h3 id="what-s-the-mnist-handwritten-digits-data-set-">What&#39;s the MNIST handwritten digits data set?</h3>
<p><a href="http://yann.lecun.com/exdb/mnist/">This data set</a> for training simple machine learning networks.</p>
<h3 id="what-s-building-a-convolutional-neural-network-step-by-step-">What&#39;s &quot;Building a Convolutional Neural Network Step By Step?&quot;</h3>
<p>An assignment in <a href="https://www.coursera.org/learn/convolutional-neural-networks?specialization=deep-learning#syllabus">this Coursera sequence on machine learning</a> taught by Dr. Andrew Ng. An outstanding course sequence for anyone who wants to get started in the field.</p>
<h3 id="who-s-andrew-ng-">Who&#39;s Andrew Ng?</h3>
<p><a href="https://en.wikipedia.org/wiki/Andrew_Ng">Dr. Andrew Ng</a> is the founder of the Google Brian Deep Learning Project; former Chief Scientist at Baidu; current pioneer of a variety of AI-related projects; an adjunct professor at Stanford; and an all-around excellent instructor.</p>
<h2 id="high-level-project-details">High-Level Project Details</h2>
<h3 id="how-does-this-project-differ-from-the-coursera-example-">How does this project differ from the Coursera example?</h3>
<p>Several improvements:</p>
<ul>
<li><p>Cleaner code. The Coursera example relies on global functions and variables passed around in dictionary caches. This project repackages the functionality into simple Python classes.</p>
</li>
<li><p>Consolidated code. The Coursera example presents the code in a set of Jupyter blocks with big chunks of exposition and unit tests in between. This project consolidates the model functionality into a small script that is easily studied.</p>
</li>
<li><p>Complete code. The Coursera example lacks a flattening layer and weight updates, and details such as fully-connected layers, weight updates, the softmax function, categorical cross-entropy loss function, and training regimen are presented only in other lessons. This project provides all of the functionality needed to train and use a variety of network architectures.</p>
</li>
<li><p>Application. The Coursera example develops a CNN, but does not apply it to any problem. This project provides an application of any model to the MNIST handwritten digits database.</p>
</li>
<li><p>Optimization. This project includes an alternative implementation of the convolutional and pooling layers that run equivalently, that can be easily dropped into place, and that run approximately 1,000 times as fast as the naive implementation.</p>
</li>
</ul>
<h3 id="what-python-packages-does-this-code-require-">What Python packages does this code require?</h3>
<p>Only NumPy and Requests (which is used to retrieve the data files from Yann LeCun&#39;s website).</p>
<h3 id="how-do-i-use-it-">How do I use it?</h3>
<p>To run the MNIST database with a non-CNN (flat) machine learning model:</p>
<pre><code>python3 mnist<span class="hljs-selector-class">.py</span> flat
</code></pre><p>To run the MNIST database with a CNN machine learning model with the stride groups implementation:</p>
<pre><code>python3 mnist<span class="hljs-selector-class">.py</span> cnn
</code></pre><p>To run the MNIST database with a CNN machine learning model with the naive implementation:</p>
<pre><code>python3 mnist<span class="hljs-selector-class">.py</span> cnn naive
</code></pre><h3 id="how-do-i-build-my-own-network-architecture-">How do I build my own network architecture?</h3>
<p>The syntax is TensorFlow-like - just provide an array of layer objects:</p>
<pre><code>    l1 = ConvLayer(<span class="hljs-number">32</span>, <span class="hljs-number">3</span>)            # <span class="hljs-number">32</span> <span class="hljs-number">3</span>x3 filters, stride <span class="hljs-number">1</span> (<span class="hljs-section">default</span>), zero padding (<span class="hljs-section">default</span>)
    l2 = PoolLayer_Max(<span class="hljs-number">2</span>)            # <span class="hljs-number">2</span>x2 pooling
    l3 = FlatLayer()                 # flattening layer
    l4 = FCLayer_ReLU(<span class="hljs-number">100</span>)           # <span class="hljs-number">100</span>-neuron dense layer, ReLU activation
    l5 = FCLayer_Softmax(<span class="hljs-number">10</span>)         # <span class="hljs-number">10</span>-layer dense layer, softmax (per-mini-batch) activation
    net = Net([l1, l2, l3, l4, l5])  # sequential network with all five layers
</code></pre><h3 id="wait-don-t-i-have-to-specify-the-size-of-the-input-to-each-layer-">Wait - don&#39;t I have to specify the size of the input to each layer?</h3>
<p>No. In this implementation, all of the weights are initialized at the beginning of training, so each layer figures out its parameter set based on the dimensions of the first mini-batch.</p>
<h3 id="how-do-i-train-and-use-the-network-">How do I train and use the network?</h3>
<p>Training using one mini-batch:</p>
<pre><code><span class="hljs-built_in">net</span>.train(mini_batch, learning_rate)  # returns (<span class="hljs-built_in">copy</span> of layer <span class="hljs-built_in">set</span>, CCE, CE)
</code></pre><p>Evaluation with input tensor X and a label set Y (<em>e.g.</em>, test set):</p>
<pre><code><span class="hljs-selector-tag">net</span><span class="hljs-selector-class">.evaluate</span>(X, Y)                    # <span class="hljs-selector-tag">returns</span> (output tensor, CCE, CE)
</code></pre><p>Prediction for input tensor X:</p>
<pre><code><span class="hljs-keyword">net</span>.<span class="hljs-keyword">predict</span>(X)                        # returns output tensor
</code></pre><h2 id="project-theory-and-mechanics">Project Theory and Mechanics</h2>
<h3 id="what-are-the-variables-used-in-the-classes-and-algorithms-">What are the variables used in the classes and algorithms?</h3>
<ul>
<li><p><code>W</code> and <code>b</code> are the weight vector and bias vector. (The FC layers don&#39;t have a separate bias vector: the bias is tacked onto the end of the weight vector, and the input tensor to the layer is augmented with a 1 so that the bias is always fully activated.)</p>
</li>
<li><p><code>f_w</code> is the size (width and height) of the filters. <code>f_w = 2</code> specifies a 2x2 convolutional filter.</p>
</li>
<li><p><code>n_f</code> is the number of filters in a convolutional layer, which is also the number of output channels from the convolutional layer.</p>
</li>
<li><p><code>n_m</code> is the number of samples in the input tensor for the current mini-batch. Might vary from one mini-batch to the next (e.g., splitting a training set with 100 inputs into three mini-batches).</p>
</li>
<li><p><code>n_c</code> is the number of channels in the input to the layer. (Could be the number of color channels in an image for the lowest-level layer, or the number of filters in a preceding convolutional layer.)</p>
</li>
<li><p><code>p</code> and <code>s</code> are padding and stride. A padding of 0 is the same as the &quot;valid&quot; padding option in TensorFlow. If you want &quot;same&quot; padding, then choose a suitable value of <code>p</code> such that <code>p = ((s - 1) * ih - s + fw)/2</code> is an integer.</p>
</li>
<li><p><code>ih</code> and <code>iw</code> are the input height and width of each input to the layer, after padding.</p>
</li>
<li><p><code>oh</code> and <code>ow</code> are the output height and width of each output of the layer, after padding.</p>
</li>
<li><p><code>Z</code> is the product of the weights and biases. In most of the layer types, it is also the output of the layer.</p>
</li>
<li><p><code>A</code> is the activation of the layer, after applying an activation function (such as ReLU, sigmoid, or softmax) to <code>Z</code>.</p>
</li>
<li><p><code>dZ</code> is the gradient that the layer receives and applies to its weights during backpropagation from the following layer (or as calculated from the loss function, for the last layer). The FCLayers actually receive <code>dA</code>, the gradient of the activation function, and then run it backward through a first derivative of the activation function to calculate <code>dZ</code>. The other layer types don&#39;t have an activation function, and so receive <code>dZ</code> directly.</p>
</li>
<li><p><code>dW</code> and <code>db</code> are the components of the gradient to be applied to the weights and biases, respectively, to perform gradient-descent optimization in pursuit of the objective function (which is categorical cross-entropy). PoolLayer and FlatLayer have no trainable parameters, so these steps are skipped.</p>
</li>
<li><p><code>dA_prev</code> is the gradient that passes backward through this layer to the previous layer so that it can also apply gradient-descent-based weight optimization. It is calculated by multiplying <code>dZ</code> by the weights (but not the biases, since they are constants that are factored out by the first derivative).</p>
</li>
<li><p><code>cce</code> is categorical cross-entropy - <em>i.e.</em>, the sum of the vector distances between each output and the expected label, summed over the mini-batch.</p>
</li>
<li><p><code>ce</code> is classification error - the number of incorrect answers in the mini-batch.</p>
</li>
</ul>
<h3 id="why-is-cnn_numpy-py-so-slow-isn-t-it-based-on-numpy-">Why is <code>cnn_numpy.py</code> so slow? Isn&#39;t it based on NumPy?</h3>
<p>The heart of the convolutional and pooling layers in &quot;Build a Convolutional Neural Network Step By Step&quot; is a four-layer Python loop. Here is the one from the ConvLayer forward pass:</p>
<pre><code><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-keyword">self</span>.n_m):
    <span class="hljs-keyword">for</span> h <span class="hljs-keyword">in</span> range(<span class="hljs-keyword">self</span>.oh):
        <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> range(<span class="hljs-keyword">self</span>.ow):
            <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> range(<span class="hljs-keyword">self</span>.n_f):
                <span class="hljs-keyword">self</span>.Z[i, h, w, f] = np.<span class="hljs-keyword">self</span>.input[i, <span class="hljs-symbol">ih1:</span>ih2, <span class="hljs-symbol">iw1:</span>iw2, <span class="hljs-symbol">:</span>] * <span class="hljs-keyword">self</span>.W[<span class="hljs-symbol">:</span>, <span class="hljs-symbol">:</span>, <span class="hljs-symbol">:</span>, f])
                <span class="hljs-keyword">self</span>.Z += <span class="hljs-keyword">self</span>.b[<span class="hljs-symbol">:</span>, <span class="hljs-symbol">:</span>, <span class="hljs-symbol">:</span>, f]
</code></pre><p>This four-layer loop is used in both the forward pass and the backward pass of the convolutional layer and the pooling layers.</p>
<p>Consider applying this implementation to the MNIST handwritten digits data set, which features 70,000 images of size 28x28 and only one channel. A basic CNN architecture might include a convolutional layer with 32 filters (<code>n_f = 32</code>) of size 3x3x1 and a stride of one (resulting in <code>self.oh = self.ow = 26</code>), followed by a pooling layer. A 95% train/test split results in a training set of 65,500 images.</p>
<p>For the forward pass of the convolutional layer for one epoch of the training data set, the inner calculations of self.Z will run (<code>n_m * oh * ow * n_f = 65,500 * 26 * 26 * 32 = 14,168,960,000</code>) times. </p>
<p>That&#39;s 14 <em>trillion</em> calculations, for the forward pass only of one convolutional layer, for <em>one epoch</em>. The backpropagation pass executes the same loop, so another 14 <em>trillion</em> calculations per epoch.</p>
<p>While NumPy is a very fast library, it simply cannot perform 28 trillion operations in anything resembling a reasonable amount of time. (The pooling layers are similarly inefficient, but on a much smaller scale.)</p>
<p>On my machine, the ConvLayer architecture above this architecture is able to train on about <em>two seconds per input sample</em> - as in: 130,000 seconds, or 36 hours, for one epoch. It is practically impossible to see it learning anything with this performance.</p>
<h3 id="how-is-cnn_numpy_sg-py-different-than-cnn_numpy-py-">How is <code>cnn_numpy_sg.py</code> different than <code>cnn_numpy.py</code>?</h3>
<p>The optimized implementations have an identical FlatLayer, FCLayer, and Network classes. Both ConvLayer and PoolLayer replace the four-layer loop with a two-layer iteration over the number of stride groups. This is, at most, the area of one filter (<em>i.e.</em>, a 3x3 filter has <em>at most</em> nine stride groups). For operations where the stride equals the filter size, the <em>entire</em> forward and backward passes require exactly one iteration of this loop - each of the forward pass and backward pass are calculated, in entirety, with one massive matrix multiplication.</p>
<h3 id="what-s-a-stride-group-">What&#39;s a stride group?</h3>
<p>Stride groups are a novel optimization technique for performing convolutional and pooling operations. The idea is to replace iteration, as much as possible, with a reshaping of the input and weight tensors so that each element in each filter is multiplied together with a huge number of elements in the input tensor. So instead of iterating through the input tensors <em>trillions</em> of times to perform small calculations, stride groups enable NumPy to iterate only a few times, <em>in some cases only once</em>, to calculate the forward and backward passes.</p>
<h3 id="no-seriously-what-s-a-stride-group-">No, seriously, what&#39;s a stride group?</h3>
<p>A simple example will help. Consider a 2x2 convolutional filter with four elements:</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>B</td>
</tr>
<tr>
<td>C</td>
<td>D</td>
</tr>
</tbody>
</table>
<p>Consider the convolution of this filter over this 4x4 input (with a stride of 1):</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>5</td>
<td>6</td>
<td>7</td>
<td>8</td>
</tr>
<tr>
<td>9</td>
<td>10</td>
<td>11</td>
<td>12</td>
</tr>
<tr>
<td>13</td>
<td>14</td>
<td>15</td>
<td>16</td>
</tr>
</tbody>
</table>
<p>In naive convolution, this calculation is performed by sliding the filter over the image, performing a 2x2 element-wise multiplication at each position, and adding up the results. <code>cnn_numpy.py</code> does this, but performing this small 2x2 multiplication over 65,500 input samples (a 95% set of the MNIST data set), where each image is 26x26 (so 24x24 positions for each image), and for each filter, is intensely slow.</p>
<p>Instead, consider which elements above <em>actually</em> get multiplied by each element of the filter. If the output of the layer (<code>Z</code>) is this:</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>E</td>
<td>F</td>
</tr>
<tr>
<td>G</td>
<td>H</td>
</tr>
</tbody>
</table>
<p>...then each of these is calculated based on a multiplication of the filter with a subset of the pixels:</p>
<pre><code>E = A * (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>)
F = B * (<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>)
G = C * (<span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">9</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">13</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>)
H = D * (<span class="hljs-number">6</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">10</span>, <span class="hljs-number">11</span>, <span class="hljs-number">12</span>, <span class="hljs-number">14</span>, <span class="hljs-number">15</span>, <span class="hljs-number">16</span>)
</code></pre><p>
<p>In order to break down this problem, consider that the filter strides over the input nine times:</p>
<p><img src="images/strides.png" alt="Convolution with Strides"></p>
<p>However, the iteration is still proportional to the size of the input, the number of filters, and the fine-grained nature of the stride. It will still be computationally inefficient to apply this design to data sets with larger images or networks with multiple layers.</p>
<p>We can do better. It would be great to grab as many of these pixels as we can during one pass through the input tensor - that&#39;s the sort of enormous calculation that NumPy does very well. One way to achieve this would be to reshape the array so that the elements against which each filter element are grouped together. NumPy can do that, too.</p>
<p>Unfortunately, it&#39;s not quite as simple as reshaping the array - because, as you&#39;ll notice, some of those inputs are repeated. Element 2 in the input is multiplied by both filter elements A and B. Element 6 in the input is multiplied by <em>all four</em> filter elements. So simply reshaping the array won&#39;t be enough.</p>
<p>Instead, we can divide the positions of the filter over the input into <em>subsets</em> of <em>non-overlapping</em> filter positions. For each subset of filter positions, each input element is included <em>at most once</em>. A careful slicing and reshaping of the array could then group together all of the input elements for each filter element and perform the weight-vector-by-input-tensor multiplication (while excluding all of the input elements that aren&#39;t covered by any filter position in this subset).</p>
<p>For instance, this 2x2 convolution has four stride groups:</p>
<p><img src="images/stride-groups.png" alt="Convolution with Stride Groups"></p>
<p>Thus, in the first stride group:</p>
<pre><code>E = A * (<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">9</span>, <span class="hljs-number">11</span>)
F = B * (<span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">10</span>, <span class="hljs-number">12</span>)
G = C * (<span class="hljs-number">5</span>, <span class="hljs-number">7</span>, <span class="hljs-number">9</span>, <span class="hljs-number">11</span>)
H = D * (<span class="hljs-number">6</span>, <span class="hljs-number">8</span>, <span class="hljs-number">14</span>, <span class="hljs-number">16</span>)
</code></pre><p>In the second stride group:</p>
<pre><code><span class="hljs-attr">E</span> = A * (<span class="hljs-number">2</span>, <span class="hljs-number">10</span>)
<span class="hljs-attr">F</span> = B * (<span class="hljs-number">3</span>, <span class="hljs-number">11</span>)
<span class="hljs-attr">G</span> = C * (<span class="hljs-number">6</span>, <span class="hljs-number">14</span>)
<span class="hljs-attr">H</span> = D * (<span class="hljs-number">7</span>, <span class="hljs-number">15</span>)
</code></pre><p>In the third stride group:</p>
<pre><code><span class="hljs-attr">E</span> = A * (<span class="hljs-number">5</span>, <span class="hljs-number">7</span>)
<span class="hljs-attr">F</span> = B * (<span class="hljs-number">6</span>, <span class="hljs-number">8</span>)
<span class="hljs-attr">G</span> = C * (<span class="hljs-number">9</span>, <span class="hljs-number">11</span>)
<span class="hljs-attr">H</span> = D * (<span class="hljs-number">10</span>, <span class="hljs-number">12</span>)
</code></pre><p>And in the fourth stride group:</p>
<pre><code><span class="hljs-attr">E</span> = A * (<span class="hljs-number">6</span>)
<span class="hljs-attr">F</span> = B * (<span class="hljs-number">7</span>)
<span class="hljs-attr">G</span> = C * (<span class="hljs-number">10</span>)
<span class="hljs-attr">H</span> = D * (<span class="hljs-number">11</span>)
</code></pre><p>Each stride group, then, is a collection of non-overlapping positions of the filter, where the entire set of input elements that are multiplied by each filter element in all of those positions are grouped together at the end of the array.</p>
<h3 id="why-are-stride-groups-better-">Why are stride groups better?</h3>
<p>Because each stride group allows a big slice of the array to be aligned and multiplied with the corresponding filter elements on one pass through the input tensor. This tremendously reduces the number of stride groups that must be processed, <em>i.e.</em>, the number of iterations or passes through the array for each forward propagation / backpropagation operation. In fact, the number of stride groups is <em>at most</em> the area of the filter - e.g., <em>at most</em> nine iterations for a 3x3 filter - and typically fewer. If the stride matches the filter width, then the number of stride group is <em>one</em>: forward propagation and backpropagation are each performed with a single, enormous matrix multiplication.</p>
<p>The number of stride groups is based on the filter size and the stride. It is also based on a <em>modulo</em> of the input widths and heights, but it is not <em>proportional to</em> the input widths and heights. And it is completely irrespective of the number of inputs, the number of channels, and the number of filters.</p>
<h3 id="could-cnn_numpy_sg-py-be-further-optimized-">Could <code>cnn_numpy_sg.py</code> be further optimized?</h3>
<p>Certainly. I am a NumPy amateur, and my code is pretty clumsy. I presume that a lot of operations could be equivalently performed in a much more efficient manner.</p>
<h3 id="should-i-optimize-it-">Should I optimize it?</h3>
<p>Probably not. This code will never compete with TensorFlow or PyTorch. Your time may be better spent on those. But if you&#39;re really itching to sharpen your NumPy skills or optimization, this might provide good practice.</p>
<h3 id="i-have-questions-">I have questions...</h3>
<p>Please feel free to contact me: <a href="mailto:david@djstein.com">david@djstein.com</a>, or try posting on <a href="https://www.reddit.com/r/deeplearning">/r/deeplearning</a> - they&#39;re pretty friendly.</p>
<hr />
<h3><a href="https://www.djstein.com/projects/">More Projects</a></H3>
<hr />
</body>
</html>
